# Simplified LocalAI setup - uses built-in model gallery
services:
  localai:
    image: quay.io/go-skynet/local-ai:latest-aio-cpu
    container_name: empathic-proxy-localai
    ports:
      - "8081:8080"
    environment:
      - MODELS_PATH=/models
      - DEBUG=true
      - GALLERIES=[{"name":"model-gallery","url":"https://raw.githubusercontent.com/go-skynet/model-gallery/main/gpt-3.5-turbo.yaml"}]
    volumes:
      - ./models:/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    restart: unless-stopped

